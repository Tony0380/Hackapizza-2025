{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# RAG: Retrieval-Augmented Generation\n",
   "id": "c30e5eb98863b7c5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Caricamento di documenti PDF\n",
    "\n",
    "## Funzionamento:\n",
    "1. Si importa la funzione `load_pdfs_recursively` dal modulo `document_loaders` di LangChain.\n",
    "2. Si definisce la cartella contenente i documenti PDF.\n",
    "3. Si invoca la funzione `load_pdfs_recursively` passando il percorso della cartella come argomento.\n",
    "4. La funzione carica ricorsivamente tutti i file PDF da quella cartella e dalle sue sottocartelle.\n",
    "5. I documenti vengono restituiti come una lista di oggetti `Document`."
   ],
   "id": "be0b087a65e6d466"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "\n",
    "def load_pdfs_recursively(folder_path):\n",
    "    \"\"\"\n",
    "    Carica ricorsivamente tutti i file PDF da una cartella e dalle sue sottocartelle.\n",
    "\n",
    "    :param folder_path: Percorso della cartella principale.\n",
    "    :return: Lista di documenti caricati.\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "\n",
    "    # Scansiona la cartella e sottocartelle\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for filename in files:\n",
    "            print(f\"üìÅ Scansionando: {root}\")\n",
    "            if filename.endswith(\".pdf\"):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                print(f\"üìÑ Caricando: {file_path}\")\n",
    "\n",
    "                # Carica il PDF\n",
    "                loader = PyMuPDFLoader(file_path)\n",
    "                documents.extend(loader.load())  # Aggiunge i documenti alla lista\n",
    "\n",
    "    print(f\"‚úÖ Caricati {len(documents)} documenti da {folder_path}\")\n",
    "    return documents\n",
    "\n",
    "dataset_path = \"../HackapizzaDataset/\"\n",
    "all_pdfs = load_pdfs_recursively(dataset_path)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Caricamento di documenti HTML\n",
    "\n",
    "## Funzionamento:\n",
    "1. Si importa la funzione `load_htmls_recursively` dal modulo `document_loaders` di LangChain.\n",
    "2. Si definisce la cartella contenente i documenti HTML.\n",
    "3. Si invoca la funzione `load_htmls_recursively` passando il percorso della cartella come argomento.\n",
    "4. La funzione carica ricorsivamente tutti i file HTML da quella cartella e dalle sue sottocartelle.\n",
    "5. I documenti vengono restituiti come una lista di oggetti `Document`."
   ],
   "id": "1fc6bf6736d3273c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T15:52:23.337793Z",
     "start_time": "2025-02-19T15:52:23.321685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from langchain.document_loaders import BSHTMLLoader\n",
    "\n",
    "def load_htmls_recursively(folder_path):\n",
    "    \"\"\"\n",
    "    Carica ricorsivamente tutti i file HTML da una cartella e dalle sue sottocartelle.\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for filename in files:\n",
    "            if filename.lower().endswith((\".html\", \".htm\")):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                print(f\"üåç Caricando: {file_path}\")\n",
    "\n",
    "                try:\n",
    "                    # Forza l'uso di html.parser se lxml non funziona\n",
    "                    loader = BSHTMLLoader(file_path, bs_kwargs={\"features\": \"html.parser\"})\n",
    "                    documents.extend(loader.load())\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Errore con {file_path}: {e}\")\n",
    "\n",
    "    print(f\"‚úÖ Caricati {len(documents)} documenti HTML da {folder_path}\")\n",
    "    return documents\n",
    "\n",
    "dataset_path = \"../HackapizzaDataset/\"\n",
    "all_htmls = load_htmls_recursively(dataset_path)"
   ],
   "id": "e11864cf1ba12678",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç Caricando: ../HackapizzaDataset/Blogpost/blog_sapore_del_dune.html\n",
      "üåç Caricando: ../HackapizzaDataset/Blogpost/blog_etere_del_gusto.html\n",
      "‚úÖ Caricati 2 documenti HTML da ../HackapizzaDataset/\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Unione di documenti PDF e HTML\n",
    "\n"
   ],
   "id": "41f233a8f14a30fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def loadDocuments(folder_path):\n",
    "    documents = load_htmls_recursively(folder_path)\n",
    "    documents.extend(load_pdfs_recursively(folder_path))\n",
    "    return documents\n",
    "\n",
    "documents = loadDocuments(\"../HackapizzaDataset/\")\n",
    "print(f\"üìÑ Documenti caricati: {documents}\")  # Debug"
   ],
   "id": "bdfebc495a33699e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Chunking di documenti\n",
    "\n",
    "## Funzionamento:\n",
    "Chuking a dimensione fissa di documenti."
   ],
   "id": "2347b52026d7dd13"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "documents = loadDocuments(\"../HackapizzaDataset/\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(documents)\n"
   ],
   "id": "44fc61076ba8f7db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Embedding di chunk\n",
    "\n",
    "## Funzionamento:\n",
    "Embedding di chunk di testo utilizzando un modello preaddestrato."
   ],
   "id": "3e1e1b0968fabfb9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T15:47:36.616832Z",
     "start_time": "2025-02-19T15:47:33.640396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Inizializza il modello di embedding\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Genera gli embedding per i chunk di testo\n",
    "chunk_embeddings = embedding_model.embed_documents([chunk.page_content for chunk in chunks])"
   ],
   "id": "753384bcd63c7a47",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Indicizzamento di chuck in un vettore store\n",
    "\n",
    "## FAISS"
   ],
   "id": "d4395d3116111aae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T15:51:05.642349Z",
     "start_time": "2025-02-19T15:51:03.961107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Inizializza FAISS con gli embedding e i metadati dei chunk\n",
    "vectorstore = FAISS.from_texts(\n",
    "    texts=[chunk.page_content for chunk in chunks],\n",
    "    embedding=embedding_model\n",
    ")"
   ],
   "id": "78be4d36c03e210c",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Motore di ricerca\n",
    "\n"
   ],
   "id": "e207f49f01890cb9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T16:08:21.422680Z",
     "start_time": "2025-02-19T16:08:21.371617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = (\"chef Aurora Stellaris\")  # Query di ricerca\n",
    "results = vectorstore.similarity_search(query, k=5)  # Trova i 5 documenti pi√π simili\n",
    "\n",
    "# Stampa i risultati\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"üîπ Risultato {i+1}: {doc.page_content[:500]}...\\n\")\n"
   ],
   "id": "9260998036e8202f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Risultato 1: Ristorante \"Anima Cosmica\"\n",
      "Chef Aurora Stellaris\n",
      "Nel cuore pulsante di Pandora, dove le foreste bioluminescenti e le montagne fluttuanti si uniscono in un\n",
      "mosaico vibrante, emerge un gioiello culinario che fonde la magia di questo mondo alieno con l'eccellenza\n",
      "gastronomica. L'Anima Cosmica, guidato dall'innovativa Chef Aurora Stellaris, √® il vertice della cucina\n",
      "pandoriana, una sintesi di tradizione Na'vi e avanzata scienza culinaria....\n",
      "\n",
      "üîπ Risultato 2: Ristorante \"Le Dimensioni del Gusto\"\n",
      "Chef Executive: Aurora Celestini\n",
      "Immerso nel vibrante cuore di un sistema solare ricco di vita e delizie culinarie, il ristorante \"Le\n",
      "Dimensioni del Gusto\" √® un faro di innovazione gastronomica sul Pianeta Ego. Sotto la guida\n",
      "visionaria della Chef Aurora Celestini, questo luogo si √® affermato come una meta irresistibile\n",
      "per gli esploratori del gusto da ogni angolo della galassia....\n",
      "\n",
      "üîπ Risultato 3: L'Eco dei Sapori\n",
      "Chef Aurora Vessanti\n",
      "Nelle affascinanti colline del pianeta Ego, illuminato dalla luce dorata di un tramonto, sorge un ristorante\n",
      "unico nel suo genere. Chef Aurora Vessanti ha trasformato questa dimora storica in un luogo dove la cucina\n",
      "sfida i confini del possibile, creando un ponte tra mondi diversi. Ogni piatto √® una storia, ogni aroma un\n",
      "ricordo riaffiorato.\n",
      "Durante la sua formazione, Aurora ha scoperto un dono straordinario: la capacit√† di percepire le emozioni di...\n",
      "\n",
      "üîπ Risultato 4: Ristorante \"L'Oasi delle Dune Stellari\"\n",
      "Chef: Alessandra \"Nova\" Celestini\n",
      "Nel cuore arido e misterioso delle sabbie di Tatooine, dove il doppio tramonto tinge l'orizzonte di tonalit√†\n",
      "incredibili, si erge la nostra oasi culinaria. Qui, ogni notte, si assiste a un'esperienza che oltrepassa la\n",
      "semplice gastronomia.\n",
      "La Chef Celestini, una volta architetta interstellare del Consorzio del Sistema, trasformava mondi e creava...\n",
      "\n",
      "üîπ Risultato 5: Sinfonia Cosmica di Aurora\n",
      "Preparazione esclusiva della Chef Aurora Vessanti, la \"Sinfonia Cosmica di Aurora\" √® un viaggio tra le stelle\n",
      "e i ricordi, un piatto che cattura l'essenza stessa dell'Eco dei Sapori. Ogni boccone √® un balletto di emozioni\n",
      "e sapori sospeso nel tempo e nello spazio.\n",
      "Al centro del piatto, il Riso di Cassandra posa come un cielo cristallino, cotto alla perfezione mediante\n",
      "Ebollizione Magneto-Cinetica Pulsante, che esalta i sapori del chicco senza compromettere la sua...\n",
      "\n"
     ]
    }
   ],
   "execution_count": 72
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
